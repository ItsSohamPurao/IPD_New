{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c428f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE SELECTION: Permutation_Importance_RF\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from base_module import (\n",
    "    get_preprocessed_data,\n",
    "    train_and_evaluate,\n",
    "    save_model_results,\n",
    "    SVM_PARAMS,\n",
    "    RANDOM_STATE\n",
    ")\n",
    "import time\n",
    "\n",
    "ALGORITHM_NAME = \"Permutation_Importance_RF\"\n",
    "# !! IMPORTANT: Update this path to your local file path !!\n",
    "DATA_PATH = r'D:\\ACTUAL STUDY MATERIAL\\IPD\\Data\\diabetic_data.csv'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"FEATURE SELECTION: {ALGORITHM_NAME}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdeb413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading and Preprocessing Data ---\n",
      "Loading data from D:\\ACTUAL STUDY MATERIAL\\IPD\\Data\\diabetic_data.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ACTUAL STUDY MATERIAL\\IPD\\src\\Notebook\\base_module.py:32: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, na_values='?')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data shape: (98053, 43)\n",
      "Engineering features...\n",
      "Engineered data shape: (98053, 41)\n",
      "\n",
      "Preprocessing data...\n",
      "Ordinal Encoding 31 features...\n",
      "Encoded features: 40\n",
      "  - Numeric: 9\n",
      "  - Categorical (Ordinal): 31\n",
      "\n",
      "Starting with 40 encoded features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Loading and Preprocessing Data ---\")\n",
    "\n",
    "X_train_encoded, X_test_encoded, y_train, y_test, \\\n",
    "    all_encoded_features, all_original_features, feature_mapping = \\\n",
    "    get_preprocessed_data(DATA_PATH)\n",
    "\n",
    "print(f\"\\nStarting with {len(all_encoded_features)} encoded features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613d22bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying Permutation_Importance_RF (Sklearn Implementation) ---\n",
      "Fitting RandomForest model to calculate permutation importances...\n",
      "✓ Model fitting complete in 0.02 minutes\n",
      "\n",
      "Calculating permutation importances (this may take a minute)...\n",
      "✓ Permutation importance calculated in 0.55 minutes\n",
      "\n",
      "Feature Selection Results:\n",
      "  Selected: 28 features\n",
      "  Eliminated: 12 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Applying {ALGORITHM_NAME} (Sklearn Implementation) ---\")\n",
    "\n",
    "# --- 1. Train a model to get importances from ---\n",
    "# This model is ONLY for calculating importances, not final evaluation.\n",
    "# RandomForest is a good, standard choice.\n",
    "estimator = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Fitting RandomForest model to calculate permutation importances...\")\n",
    "start_time = time.time()\n",
    "estimator.fit(X_train_encoded, y_train)\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f\"✓ Model fitting complete in {elapsed:.2f} minutes\")\n",
    "\n",
    "# --- 2. Calculate Permutation Importance ---\n",
    "# We calculate importance on the *test* set (or a validation set)\n",
    "# to see which features generalize best.\n",
    "# 'f1' is a good scoring metric for imbalanced data.\n",
    "print(\"\\nCalculating permutation importances (this may take a minute)...\")\n",
    "start_time = time.time()\n",
    "perm_importance = permutation_importance(\n",
    "    estimator,\n",
    "    X_test_encoded,  # Use test set for unbiased importance\n",
    "    y_test,\n",
    "    n_repeats=10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f\"✓ Permutation importance calculated in {elapsed:.2f} minutes\")\n",
    "\n",
    "# --- 3. Rank and Select Features ---\n",
    "importances = perm_importance.importances_mean\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': all_encoded_features,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Select top 70% of features (like your FIFA notebook)\n",
    "n_select = int(0.7 * len(all_encoded_features))\n",
    "selected_features = importances_df['feature'].head(n_select).tolist()\n",
    "\n",
    "# --- 4. Filter Datasets ---\n",
    "# Get the column indices in the *original* encoded data\n",
    "original_indices_mapping = {feat: i for i, feat in enumerate(all_encoded_features)}\n",
    "final_selected_original_indices = [original_indices_mapping[feat] for feat in selected_features]\n",
    "\n",
    "X_train_selected = X_train_encoded[:, final_selected_original_indices]\n",
    "X_test_selected = X_test_encoded[:, final_selected_original_indices]\n",
    "\n",
    "print(f\"\\nFeature Selection Results:\")\n",
    "print(f\"  Selected: {len(selected_features)} features\")\n",
    "print(f\"  Eliminated: {len(all_encoded_features) - len(selected_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f4fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Model on Permutation_Importance_RF-Selected Features ---\n",
      "\n",
      "Training SVM classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ACTUAL STUDY MATERIAL\\IPD\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "\n",
      "Model Performance:\n",
      "  Accuracy: 0.5978\n",
      "  Precision (class 0): 0.9065\n",
      "  Recall (class 0): 0.6095\n",
      "  F1-score (class 0): 0.7289\n",
      "  Precision (class 1): 0.1414\n",
      "  Recall (class 1): 0.5056\n",
      "  F1-score (class 1): 0.2210\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Training Model on {ALGORITHM_NAME}-Selected Features ---\")\n",
    "\n",
    "clf, y_pred, report = train_and_evaluate(\n",
    "    X_train_selected, X_test_selected,\n",
    "    y_train, y_test,\n",
    "    **SVM_PARAMS\n",
    ")\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Accuracy: {report['accuracy']:.4f}\")\n",
    "print(f\"  Precision (class 0): {report['0']['precision']:.4f}\")\n",
    "print(f\"  Recall (class 0): {report['0']['recall']:.4f}\")\n",
    "print(f\"  F1-score (class 0): {report['0']['f1-score']:.4f}\")\n",
    "print(f\"  Precision (class 1): {report['1']['precision']:.4f}\")\n",
    "print(f\"  Recall (class 1): {report['1']['recall']:.4f}\")\n",
    "print(f\"  F1-score (class 1): {report['1']['f1-score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63660ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving Results ---\n",
      "\n",
      "Saving results for: Permutation_Importance_RF\n",
      "✓ Appended to D:\\ACTUAL STUDY MATERIAL\\IPD\\src\\Results\\study_results.csv\n",
      "✓ Saved to D:\\ACTUAL STUDY MATERIAL\\IPD\\src\\Results\\permutation_importance_rf_results.json\n",
      "\n",
      "  Original: 28/40 features\n",
      "  Encoded:  28/40 features\n",
      "  Accuracy: 0.5978\n",
      "  F1 (class 1): 0.2210\n",
      "\n",
      "======================================================================\n",
      "Permutation_Importance_RF COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Saving Results ---\")\n",
    "\n",
    "save_model_results(\n",
    "    algorithm_name=ALGORITHM_NAME,\n",
    "    selected_encoded_features=selected_features,\n",
    "    all_encoded_features=all_encoded_features,\n",
    "    all_original_features=all_original_features,\n",
    "    feature_mapping=feature_mapping,\n",
    "    report=report,\n",
    "    results_csv='study_results.csv'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{ALGORITHM_NAME} COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
