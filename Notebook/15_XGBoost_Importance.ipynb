{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304eeb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE SELECTION: XGBoost_Importance\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from base_module import (\n",
    "    get_preprocessed_data,\n",
    "    train_and_evaluate,\n",
    "    save_model_results,\n",
    "    SVM_PARAMS,\n",
    "    RANDOM_STATE\n",
    ")\n",
    "import time\n",
    "\n",
    "ALGORITHM_NAME = \"XGBoost_Importance\"\n",
    "# !! IMPORTANT: Update this path to your local file path !!\n",
    "DATA_PATH = r'D:\\ACTUAL STUDY MATERIAL\\IPD\\Data\\diabetic_data.csv'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"FEATURE SELECTION: {ALGORITHM_NAME}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b202eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading and Preprocessing Data ---\n",
      "Loading data from D:\\ACTUAL STUDY MATERIAL\\IPD\\Data\\diabetic_data.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ACTUAL STUDY MATERIAL\\IPD\\src\\Notebook\\base_module.py:32: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, na_values='?')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data shape: (98053, 43)\n",
      "Engineering features...\n",
      "Engineered data shape: (98053, 41)\n",
      "\n",
      "Preprocessing data...\n",
      "Ordinal Encoding 31 features...\n",
      "Encoded features: 40\n",
      "  - Numeric: 9\n",
      "  - Categorical (Ordinal): 31\n",
      "\n",
      "Starting with 40 encoded features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Loading and Preprocessing Data ---\")\n",
    "\n",
    "X_train_encoded, X_test_encoded, y_train, y_test, \\\n",
    "    all_encoded_features, all_original_features, feature_mapping = \\\n",
    "    get_preprocessed_data(DATA_PATH)\n",
    "\n",
    "print(f\"\\nStarting with {len(all_encoded_features)} encoded features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da32e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying XGBoost_Importance (SelectFromModel) ---\n",
      "Using scale_pos_weight for imbalance: 7.86\n",
      "Fitting XGBoost model to find feature importances...\n",
      "✓ XGBoost fitting complete in 0.03 minutes\n",
      "\n",
      "Feature Selection Results:\n",
      "  Selected: 20 features (Threshold: 'median')\n",
      "  Eliminated: 20 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Applying {ALGORITHM_NAME} (SelectFromModel) ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- 1. Calculate scale_pos_weight for imbalanced data ---\n",
    "# This helps XGBoost pay more attention to the rare positive class (1)\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Using scale_pos_weight for imbalance: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# --- 2. Define the Estimator ---\n",
    "# We use XGBClassifier for this classification problem\n",
    "estimator = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# --- 3. Fit the model ---\n",
    "print(\"Fitting XGBoost model to find feature importances...\")\n",
    "estimator.fit(X_train_encoded, y_train)\n",
    "\n",
    "# --- 4. Initialize SelectFromModel ---\n",
    "# Select features with importance > median importance\n",
    "selector = SelectFromModel(estimator, prefit=True, max_features=28)\n",
    "\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f\"✓ XGBoost fitting complete in {elapsed:.2f} minutes\")\n",
    "\n",
    "# --- 5. Get Results ---\n",
    "X_train_selected = selector.transform(X_train_encoded)\n",
    "X_test_selected = selector.transform(X_test_encoded)\n",
    "\n",
    "selected_mask = selector.get_support()\n",
    "selected_features = [all_encoded_features[i] for i, selected in enumerate(selected_mask) if selected]\n",
    "\n",
    "print(f\"\\nFeature Selection Results:\")\n",
    "print(f\"  Selected: {len(selected_features)} features (Threshold: 'median')\")\n",
    "print(f\"  Eliminated: {len(all_encoded_features) - len(selected_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9773390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Model on XGBoost_Importance-Selected Features ---\n",
      "\n",
      "Training SVM classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ACTUAL STUDY MATERIAL\\IPD\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "\n",
      "Model Performance:\n",
      "  Accuracy: 0.4118\n",
      "  Precision (class 0): 0.8572\n",
      "  Recall (class 0): 0.4044\n",
      "  F1-score (class 0): 0.5495\n",
      "  Precision (class 1): 0.0913\n",
      "  Recall (class 1): 0.4704\n",
      "  F1-score (class 1): 0.1529\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Training Model on {ALGORITHM_NAME}-Selected Features ---\")\n",
    "\n",
    "clf, y_pred, report = train_and_evaluate(\n",
    "    X_train_selected, X_test_selected,\n",
    "    y_train, y_test,\n",
    "    **SVM_PARAMS\n",
    ")\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Accuracy: {report['accuracy']:.4f}\")\n",
    "print(f\"  Precision (class 0): {report['0']['precision']:.4f}\")\n",
    "print(f\"  Recall (class 0): {report['0']['recall']:.4f}\")\n",
    "print(f\"  F1-score (class 0): {report['0']['f1-score']:.4f}\")\n",
    "print(f\"  Precision (class 1): {report['1']['precision']:.4f}\")\n",
    "print(f\"  Recall (class 1): {report['1']['recall']:.4f}\")\n",
    "print(f\"  F1-score (class 1): {report['1']['f1-score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9402c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving Results ---\n",
      "\n",
      "Saving results for: XGBoost_Importance\n",
      "✓ Appended to D:\\ACTUAL STUDY MATERIAL\\IPD\\src\\Results\\study_results.csv\n",
      "✓ Saved to D:\\ACTUAL STUDY MATERIAL\\IPD\\src\\Results\\xgboost_importance_results.json\n",
      "\n",
      "  Original: 20/40 features\n",
      "  Encoded:  20/40 features\n",
      "  Accuracy: 0.4118\n",
      "  F1 (class 1): 0.1529\n",
      "\n",
      "======================================================================\n",
      "XGBoost_Importance COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Saving Results ---\")\n",
    "\n",
    "save_model_results(\n",
    "    algorithm_name=ALGORITHM_NAME,\n",
    "    selected_encoded_features=selected_features,\n",
    "    all_encoded_features=all_encoded_features,\n",
    "    all_original_features=all_original_features,\n",
    "    feature_mapping=feature_mapping,\n",
    "    report=report,\n",
    "    results_csv='study_results.csv'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{ALGORITHM_NAME} COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
